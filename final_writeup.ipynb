{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a05fd21",
   "metadata": {},
   "source": [
    "Anshuman Ranjan\n",
    "# Final Report #\n",
    "\n",
    "1. Generate learning curves for the validation and training setes. Discuss what trends you\n",
    "observe in performance.\n",
    "    Overall trend: For all models, as the number of epochs progresses the loss (predicted vs actual) gets closer to 0.\n",
    "2. Evaluate the model on the testing set and report accuracy, along with precision and recall.\n",
    "\n",
    "Analysis:\n",
    "- For all comparisons below, the following metrics were held constant, and only 1 metric was changed at a time:\n",
    "    - DEFAULT_HIDDEN = 128\n",
    "    - DEFAULT_LAYERS = 2\n",
    "    - DEFAULT_SEQ = 50\n",
    "    - DEFAULT_MODEL = \"lstm\"\n",
    "* Impact of sequence length: <br> \n",
    "    Increasing the sequence length had a variable impact on training metrics. As the sequence length grew from 10 to 50, there was a marked improvement in training metrics. The test accuracy, precision, and recall all increased, and the learning rate increased sharply from 19 to 14 epochs. But when the sequence length was set to 100, the learning rate fell back to 18 epochs, the recall fell slightly (possibly negligible) and the validation loss curve became a lot more jagged. This indicates that there is a point of diminishing returns with respect to a very large sequence length being used, potentially due to vanishing gradients (It is worth noting that the comparison was done using lstm model, the results could differ with a different training model that benefits from larger temporal context)\n",
    "    <br><br>\n",
    "* Effect of bidirectionality: <br>    \n",
    "    When comparing the results of the LSTM and BiLSTM models, it can be seen that the LSTM model completed training in 11 epochs, while the BiLSTM model completed the same training in 18 epochs. The BiLSTM model did achieve a slightly higher test accuracy, and precision, but the graph also shows that the validation testing on the BiLSTM model had a higher loss spikes than the training curve. This could indicate that there was overfitting performed by the BiLSTM model. In conclusion, LSTM may be the better option (for the default sequence length of 50) as it provides the same general accuracy at a much faster learning rate without overfitting.\n",
    "    <br><br>\n",
    "* Benefit of CNN feature extraction: <br> \n",
    "    The CNNLSTM model had a sharp impact on the learning curve. The training was completed in 8 epochs with almost 100% accuracy, precision, and recall. While this level of accuracy could just be a result of a favorable dataset split, it still indicates that adding a convolutional layer prior to the RNN improves the model's ability to capture local patterns in the audio data and use it to accurately detect speech.\n",
    "    <br><br>\n",
    "* Impact of hidden units and number of layers: <br> \n",
    "    Increasing the number of hidden units had a clear positive impact on training performance. As the number of hidden units increased from 64 to 256, the learning rate increased, and the loss curve stabilized (there was slight overfitting in all three variants of the hidden unit models)\n",
    "    Increasing the number of layers also had a positive impact on training, but only to a certain extent. While the progression of increasing layers (1 -> 2 -> 3) shows the learning rate drop consistently, there was a loss in the validation performance between layers 2 and 3. This could simply be a result of the 3-layer model having fewer epochs available to smooth out the validation curve (due to faster learning rate), so even though the results show that layer=2 is ideal, further testing should be conducted for a stronger conclusion.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
